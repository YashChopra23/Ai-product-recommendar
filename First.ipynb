{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ab234c-2328-4fe1-b618-3f69d1cb3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cyash\\yashenv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40763623-5c99-484c-9962-14cb3cd8ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\cyash\\yashenv\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf3db9a-59e4-4488-a68c-ac7e91ee05c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'intern_data_ikarus.csv' loaded successfully!\n",
      "\n",
      "Total products in the dataset: 312\n",
      "\n",
      "--- First 5 rows with the 'soup' feature ---\n",
      "                                               title  \\\n",
      "0  GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...   \n",
      "1  subrtex Leather ding Room, Dining Chairs Set o...   \n",
      "2  Plant Repotting Mat MUYETOL Waterproof Transpl...   \n",
      "3  Pickleball Doormat, Welcome Doormat Absorbent ...   \n",
      "4  JOIN IRON Foldable TV Trays for Eating Set of ...   \n",
      "\n",
      "                                                soup  \n",
      "0  GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...  \n",
      "1  subrtex Leather ding Room, Dining Chairs Set o...  \n",
      "2  Plant Repotting Mat MUYETOL Waterproof Transpl...  \n",
      "3  Pickleball Doormat, Welcome Doormat Absorbent ...  \n",
      "4  JOIN IRON Foldable TV Trays for Eating Set of ...  \n",
      "\n",
      "Processed data has been saved to 'processed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Load and Prepare the Data ---\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the CSV file.\n",
    "    # Ensure 'intern_data_ikarus.csv' is in the same folder as your notebook.\n",
    "    df = pd.read_csv('intern_data_ikarus.csv')\n",
    "    print(\"Dataset 'intern_data_ikarus.csv' loaded successfully!\")\n",
    "\n",
    "    # --- Data Cleaning and Feature Engineering ---\n",
    "\n",
    "    # Define the columns that we will use to determine product similarity.\n",
    "    feature_columns = ['title', 'brand', 'description', 'categories', 'material', 'color']\n",
    "\n",
    "    # Replace any missing values (NaN) in these columns with an empty string\n",
    "    # to prevent errors during text processing.\n",
    "    for col in feature_columns:\n",
    "        df[col] = df[col].fillna('')\n",
    "\n",
    "    # Define a function to combine all our feature columns into a single string.\n",
    "    def create_feature_soup(row):\n",
    "        return (str(row['title']) + ' ' +\n",
    "                str(row['brand']) + ' ' +\n",
    "                str(row['description']) + ' ' +\n",
    "                str(row['categories']) + ' ' +\n",
    "                str(row['material']) + ' ' +\n",
    "                str(row['color']))\n",
    "\n",
    "    # Apply the function to each row of the dataframe to create the 'soup' column.\n",
    "    df['soup'] = df.apply(create_feature_soup, axis=1)\n",
    "\n",
    "    # --- Verification ---\n",
    "\n",
    "    # Display the total number of products and the first 5 rows\n",
    "    # to show the new 'soup' column.\n",
    "    print(f\"\\nTotal products in the dataset: {len(df)}\")\n",
    "    print(\"\\n--- First 5 rows with the 'soup' feature ---\")\n",
    "    print(df[['title', 'soup']].head())\n",
    "\n",
    "    # Save the processed data to a new CSV file for the next steps.\n",
    "    df.to_csv('processed_data.csv', index=False)\n",
    "    print(\"\\nProcessed data has been saved to 'processed_data.csv'\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n--- ERROR ---\")\n",
    "    print(\"The file 'intern_data_ikarus.csv' was not found.\")\n",
    "    print(\"Please make sure the CSV file is in the same directory as your Jupyter Notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0120155-eb94-4128-bdca-d6d5b518ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\cyash\\yashenv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6dfce5-de18-4eb8-a1fd-f63771f0b6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'processed_data.csv' successfully.\n",
      "TF-IDF matrix created successfully.\n",
      "Shape of TF-IDF matrix: (312, 3572)\n",
      "Cosine similarity matrix calculated successfully.\n",
      "Shape of similarity matrix: (312, 312)\n",
      "Similarity matrix saved as 'similarity_matrix.pkl'\n",
      "Processed DataFrame saved as 'products_df.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# --- Step 2: Vectorize Text and Compute Similarity ---\n",
    "\n",
    "try:\n",
    "    # Load the processed data we created in the last step.\n",
    "    df = pd.read_csv('processed_data.csv')\n",
    "    print(\"Loaded 'processed_data.csv' successfully.\")\n",
    "\n",
    "    # --- TF-IDF Vectorization ---\n",
    "\n",
    "    # Initialize a TF-IDF Vectorizer.\n",
    "    # stop_words='english' removes common English words (like 'the', 'a', 'in')\n",
    "    # which don't help in distinguishing between products.\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # Create the TF-IDF matrix by fitting and transforming the 'soup' column.\n",
    "    # This converts each product's text 'soup' into a numerical vector.\n",
    "    tfidf_matrix = tfidf.fit_transform(df['soup'])\n",
    "    print(\"TF-IDF matrix created successfully.\")\n",
    "    print(f\"Shape of TF-IDF matrix: {tfidf_matrix.shape}\") # (num_products, num_unique_words)\n",
    "\n",
    "    # --- Cosine Similarity Calculation ---\n",
    "\n",
    "    # Calculate the cosine similarity matrix from the TF-IDF matrix.\n",
    "    # This gives us a score of how similar each product is to every other product.\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    print(\"Cosine similarity matrix calculated successfully.\")\n",
    "    print(f\"Shape of similarity matrix: {cosine_sim.shape}\") # (num_products, num_products)\n",
    "\n",
    "\n",
    "    # --- Save the Model and Processed Data ---\n",
    "\n",
    "    # Save the cosine similarity matrix to a file. This is our \"model\".\n",
    "    with open('similarity_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(cosine_sim, f)\n",
    "    print(\"Similarity matrix saved as 'similarity_matrix.pkl'\")\n",
    "\n",
    "    # We also need to save the main dataframe to easily access product titles later.\n",
    "    df.to_pickle('products_df.pkl')\n",
    "    print(\"Processed DataFrame saved as 'products_df.pkl'\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n--- ERROR ---\")\n",
    "    print(\"The file 'processed_data.csv' was not found.\")\n",
    "    print(\"Please ensure you have run the previous step successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f433700-7f47-4112-b09d-5d093da4f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'products_df.pkl' and 'similarity_matrix.pkl'\n",
      "\n",
      "--- Testing the recommendation function ---\n",
      "\n",
      "Recommendations for: 'GOYMFK 1pc Free Standing Shoe Rack, Multi-layer Metal Shoe Cap Rack With 8 Double Hooks For Living Room, Bathroom, Hallway'\n",
      "7      GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...\n",
      "82     LANTEFUL Shoe Rack Organizer Shoe Storage Cabi...\n",
      "179    Dscabomlg Foldable Shoe Storage Plastic Vertic...\n",
      "149    sogesfurniture 5 Tier Free Standing Wooden Sho...\n",
      "54     Honey-Can-Do 3-Tier Nesting Bamboo Shoe Rack S...\n",
      "Name: title, dtype: object\n",
      "\n",
      "Recommendations for: 'LOVMOR 30'' Bathroom Vanity Sink Base Cabine, Storage Cabinet with 3-Drawers on The Left, Suitable for Bathrooms, Kitchens, Laundry Rooms and Other Places.'\n",
      "12     LOVMOR 30'' Bathroom Vanity Sink Base Cabine, ...\n",
      "238    ZZQXTC Over Toilet Storage Cabinet, Bathroom S...\n",
      "184    WEENFON Storage Cabinet with Doors and Shelves...\n",
      "64     SogesHome Wood Corner Cabinet Wall Corner Stor...\n",
      "175    SP-AU-Era Mirror cabinet storage box, cosmetic...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# --- Step 3 (Corrected): Build the Recommendation Function ---\n",
    "\n",
    "# Load the saved model and data\n",
    "try:\n",
    "    products_df = pd.read_pickle('products_df.pkl')\n",
    "    cosine_sim = pickle.load(open('similarity_matrix.pkl', 'rb'))\n",
    "    print(\"Successfully loaded 'products_df.pkl' and 'similarity_matrix.pkl'\")\n",
    "\n",
    "    # Create a pandas Series of product titles with their corresponding index.\n",
    "    indices = pd.Series(products_df.index, index=products_df['title']).drop_duplicates()\n",
    "\n",
    "    # --- Define the Recommendation Function ---\n",
    "    def get_recommendations(title, cosine_sim=cosine_sim, data=products_df):\n",
    "        \"\"\"\n",
    "        This function takes a product title as input and returns\n",
    "        the top 5 most similar products.\n",
    "        \"\"\"\n",
    "        # Get the index of the product that matches the title\n",
    "        if title not in indices:\n",
    "            return f\"Product with title '{title}' not found.\"\n",
    "        \n",
    "        idx = indices[title]\n",
    "\n",
    "        # --- THIS IS THE FIX ---\n",
    "        # If the title is duplicated, idx will be a Series. We take the index of the first occurrence.\n",
    "        if isinstance(idx, pd.Series):\n",
    "            idx = idx.iloc[0]\n",
    "\n",
    "        # Get the pairwise similarity scores of all products with that product\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "        # Sort the products based on the similarity scores in descending order\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get the scores of the 5 most similar products (excluding the product itself)\n",
    "        sim_scores = sim_scores[1:6]\n",
    "\n",
    "        # Get the product indices\n",
    "        product_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "        # Return the titles of the top 5 most similar products\n",
    "        return data['title'].iloc[product_indices]\n",
    "\n",
    "    # --- Test the Recommendation Function ---\n",
    "\n",
    "    # Let's get recommendations for the first product in our dataset\n",
    "    example_product_title = products_df['title'].iloc[0]\n",
    "\n",
    "    print(\"\\n--- Testing the recommendation function ---\")\n",
    "    print(f\"\\nRecommendations for: '{example_product_title}'\")\n",
    "    recommendations = get_recommendations(example_product_title)\n",
    "    print(recommendations)\n",
    "    \n",
    "    # You can also test with another product\n",
    "    example_product_title_2 = products_df['title'].iloc[5]\n",
    "    print(f\"\\nRecommendations for: '{example_product_title_2}'\")\n",
    "    recommendations_2 = get_recommendations(example_product_title_2)\n",
    "    print(recommendations_2)\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n--- ERROR ---\")\n",
    "    print(\"Could not find 'products_df.pkl' or 'similarity_matrix.pkl'.\")\n",
    "    print(\"Please ensure you have run the previous step successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab06f926-3706-4d9d-9a44-25cd3bd708e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\cyash\\yashenv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\cyash\\yashenv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\cyash\\yashenv\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (0.4.37)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (2.26.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (2.185.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (2.41.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyash\\yashenv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a1ac7a-7056-4b50-b1a1-a900701cdb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variables from .env file.\n",
      "Google AI Model ('gemini-2.5-flash') initialized successfully.\n",
      "\n",
      "--- Testing Direct Description Generator ---\n",
      "Product Title: Boss Office Products Any Task Mid-Back Task Chair with Loop Arms in Grey\n",
      "\n",
      "--- AN ERROR OCCURRED ---\n",
      "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv  # <-- Import the new library\n",
    "\n",
    "# --- Load Environment Variables ---\n",
    "# This command looks for the .env file and loads it into the environment.\n",
    "load_dotenv()\n",
    "print(\"Loaded variables from .env file.\")\n",
    "\n",
    "# --- Step 4 (Secure): Direct API Call ---\n",
    "\n",
    "# Get the API key from the environment variables\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check if the key was found\n",
    "if not api_key:\n",
    "    print(\"--- WARNING ---\")\n",
    "    print(\"GOOGLE_API_KEY not found. Make sure you have created a .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        # Configure the API key\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        print(\"Google AI Model ('gemini-2.5-flash') initialized successfully.\")\n",
    "\n",
    "        # --- Define the generator function (no change here) ---\n",
    "        def generate_description_direct(title, brand, material):\n",
    "            prompt = f\"\"\"You are a creative marketing assistant for an e-commerce store.\n",
    "            Your task is to write a short, appealing, and creative product description\n",
    "            that is no more than two sentences long.\n",
    "\n",
    "            Product Title: {title}\n",
    "            Brand: {brand}\n",
    "            Material: {material}\n",
    "\n",
    "            Creative Description:\"\"\"\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "\n",
    "        # --- Test the function (no change here) ---\n",
    "        products_df = pd.read_pickle('products_df.pkl')\n",
    "        sample_product = products_df.iloc[15]\n",
    "\n",
    "        print(\"\\n--- Testing Direct Description Generator ---\")\n",
    "        print(f\"Product Title: {sample_product['title']}\")\n",
    "        creative_description = generate_description_direct(\n",
    "            title=sample_product['title'],\n",
    "            brand=sample_product['brand'],\n",
    "            material=sample_product['material']\n",
    "        )\n",
    "        print(\"\\nGenerated Creative Description:\")\n",
    "        print(creative_description)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa470dc3-eb6a-467d-8a2a-baf15c86eeab",
   "metadata": {},
   "source": [
    "# For the Vector Database part , Pinecone part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6491cb1c-49cd-4f92-9746-7403bb8b6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\cyash\\yashenv\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyash\\yashenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c15779-40a3-456a-80bc-31f768f8fa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22539ca8-63b6-465c-bfaa-caa21d5837ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in c:\\users\\cyash\\yashenv\\lib\\site-packages (7.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (2025.10.5)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470a7a3a-32bb-4e8e-9a52-40cbd70fa519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone client initialized.\n",
      "Index 'product-recommendations' already exists. Connecting to it.\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 305}},\n",
      " 'total_vector_count': 305,\n",
      " 'vector_type': 'dense'}\n",
      "\n",
      "SentenceTransformer model 'all-MiniLM-L6-v2' loaded.\n",
      "Loaded 312 products from 'products_df.pkl'\n",
      "\n",
      "Starting to generate embeddings and upload to Pinecone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:19<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All products have been embedded and uploaded to Pinecone! ---\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 305}},\n",
      " 'total_vector_count': 305,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm # A library to show a progress bar\n",
    "\n",
    "# --- Step 5.3: Create and Populate Pinecone Vector DB ---\n",
    "\n",
    "# --- 1. Load Keys and Initialize ---\n",
    "load_dotenv()\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not pinecone_api_key:\n",
    "    print(\"--- WARNING ---\")\n",
    "    print(\"PINECONE_API_KEY not found. Make sure it is in your .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        # Initialize Pinecone\n",
    "        pc = Pinecone(api_key=pinecone_api_key)\n",
    "        print(\"Pinecone client initialized.\")\n",
    "\n",
    "        # --- 2. Create Pinecone Index ---\n",
    "        index_name = \"product-recommendations\"\n",
    "        \n",
    "        if index_name not in pc.list_indexes().names():\n",
    "            print(f\"Index '{index_name}' not found. Creating it...\")\n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=384, # This dimension MUST match our model\n",
    "                metric=\"cosine\", # Cosine similarity is good for text\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-east-1\" # Use a free-tier region\n",
    "                )\n",
    "            )\n",
    "            print(f\"Index '{index_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Index '{index_name}' already exists. Connecting to it.\")\n",
    "\n",
    "        # Connect to the index\n",
    "        index = pc.Index(index_name)\n",
    "        print(index.describe_index_stats()) # Show stats\n",
    "\n",
    "        # --- 3. Load Embedding Model ---\n",
    "        # This model is fast and very effective for semantic search\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        print(\"\\nSentenceTransformer model 'all-MiniLM-L6-v2' loaded.\")\n",
    "\n",
    "        # --- 4. Load Data ---\n",
    "        products_df = pd.read_pickle('products_df.pkl')\n",
    "        # Ensure there are no missing 'uniq_id' values\n",
    "        products_df = products_df.dropna(subset=['uniq_id'])\n",
    "        print(f\"Loaded {len(products_df)} products from 'products_df.pkl'\")\n",
    "\n",
    "        # --- 5. Generate Embeddings and Upload ---\n",
    "        print(\"\\nStarting to generate embeddings and upload to Pinecone...\")\n",
    "        \n",
    "        # We upload in batches for efficiency\n",
    "        batch_size = 100 \n",
    "        for i in tqdm(range(0, len(products_df), batch_size)):\n",
    "            # Get a batch of products\n",
    "            batch = products_df.iloc[i:i+batch_size]\n",
    "            \n",
    "            # Get the 'soup' text\n",
    "            texts = batch['soup'].tolist()\n",
    "            # Get the unique IDs\n",
    "            ids = batch['uniq_id'].tolist()\n",
    "            \n",
    "            # Generate embeddings for the batch\n",
    "            embeddings = model.encode(texts)\n",
    "            \n",
    "            # Prepare the data for upload (id, vector)\n",
    "            vectors_to_upload = list(zip(ids, embeddings.tolist()))\n",
    "            \n",
    "            # Upload the batch to Pinecone\n",
    "            index.upsert(vectors=vectors_to_upload)\n",
    "\n",
    "        print(\"\\n--- All products have been embedded and uploaded to Pinecone! ---\")\n",
    "        print(index.describe_index_stats())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e17604-595a-48fc-a936-e50d0f568dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index 'product-recommendations'.\n",
      "SentenceTransformer model loaded.\n",
      "Product data loaded and indexed by 'uniq_id'.\n",
      "\n",
      "--- Testing Semantic Search ---\n",
      "\n",
      "Recommendations for: 'a comfortable chair for my office'\n",
      "uniq_id\n",
      "0583ef58-47cd-509b-9e6d-89a0ad8490b2    Ergonomic Office Chair,Office Chair, with Lumb...\n",
      "a0a69530-a944-589d-a036-90358cb9e485    Boss Office Products Any Task Mid-Back Task Ch...\n",
      "fe25ae1d-4a82-57ad-9bab-b9de4321fd0b    Karl home Accent Chair Mid-Century Modern Chai...\n",
      "b3a490d6-a89e-57e0-9188-706c89a156a1    Winrise Office Chair Ergonomic Desk Chair, Hig...\n",
      "e037f8af-d28c-51a1-8f1c-3f524620910e    AnRui Folding Floor Chair with Adjustable Back...\n",
      "Name: title, dtype: object\n",
      "\n",
      "Recommendations for: 'modern storage for shoes'\n",
      "uniq_id\n",
      "122c5c2a-5490-51ce-8555-9526c9698a38    LANTEFUL Shoe Rack Organizer Shoe Storage Cabi...\n",
      "feca0b89-547f-5bca-9b97-f255c5467e47    Soerreo Shoe Slot Storage Box Adjustable Shoe ...\n",
      "a10176fb-74af-5428-9aaf-2787aa4d66d2    MoNiBloom Foldable Storage Free Standing Shoes...\n",
      "30eb7c8c-21ae-5156-91fb-7d8b56eec7ac    Pinkpum Shoe Ogranizer for Closet, 12 Pack Sho...\n",
      "38587d05-ed7c-54eb-acc2-057cec374f51    Dscabomlg Foldable Shoe Storage Plastic Vertic...\n",
      "Name: title, dtype: object\n",
      "\n",
      "Recommendations for: 'something made of wood'\n",
      "uniq_id\n",
      "67a9650d-65a9-5baa-bac0-05675c468b0b    Solid Wood Wine Cabinet, bar Rack - Home Wood ...\n",
      "2c7902b4-ae0c-5ed9-9cbc-b6927d0b3347    Furinno Coffee Table with Bins, Espresso/Brown...\n",
      "7df6de67-891e-567d-b8a5-3d184440a707    FLYJOE Narrow Side Table with PU Leather Magaz...\n",
      "02f8cd17-8c4f-5c32-acc0-4af9115c6c20    Summer Desk Decor,Welcome Summer Wood Block Si...\n",
      "07b9d03a-02bc-5bc9-9133-a8e7b706cbc4    FurnitureR 27''H Round Drawer 2 Tiers Endtable...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Step 5.4: Create the Vector Search Function ---\n",
    "\n",
    "# --- 1. Load Keys and Initialize Clients ---\n",
    "load_dotenv()\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not pinecone_api_key:\n",
    "    print(\"--- WARNING ---\")\n",
    "    print(\"PINECONE_API_KEY not found. Make sure it is in your .env file.\")\n",
    "else:\n",
    "    try:\n",
    "        # Initialize Pinecone\n",
    "        pc = Pinecone(api_key=pinecone_api_key)\n",
    "        index_name = \"product-recommendations\"\n",
    "        index = pc.Index(index_name)\n",
    "        print(f\"Connected to Pinecone index '{index_name}'.\")\n",
    "\n",
    "        # Load the embedding model\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        print(\"SentenceTransformer model loaded.\")\n",
    "\n",
    "        # Load product data\n",
    "        products_df = pd.read_pickle('products_df.pkl')\n",
    "        # Set 'uniq_id' as the index for fast lookups\n",
    "        products_df = products_df.set_index('uniq_id')\n",
    "        print(\"Product data loaded and indexed by 'uniq_id'.\")\n",
    "\n",
    "        # --- 2. Define the New Recommendation Function ---\n",
    "        def get_semantic_recommendations(query, top_k=5):\n",
    "            \"\"\"\n",
    "            Gets recommendations from Pinecone based on a text query.\n",
    "            \"\"\"\n",
    "            # 1. Create the embedding for the query\n",
    "            query_embedding = model.encode(query).tolist()\n",
    "            \n",
    "            # 2. Query Pinecone\n",
    "            query_results = index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k, # Get the top 5 results\n",
    "                include_metadata=False # We only need the IDs\n",
    "            )\n",
    "            \n",
    "            # 3. Get the list of product IDs from the results\n",
    "            result_ids = [match['id'] for match in query_results['matches']]\n",
    "            \n",
    "            # 4. Look up the full product details from our dataframe\n",
    "            recommended_products = products_df.loc[result_ids]\n",
    "            \n",
    "            return recommended_products\n",
    "\n",
    "        # --- 3. Test the Function ---\n",
    "        print(\"\\n--- Testing Semantic Search ---\")\n",
    "        \n",
    "        # Test 1: A specific query\n",
    "        query1 = \"a comfortable chair for my office\"\n",
    "        print(f\"\\nRecommendations for: '{query1}'\")\n",
    "        results1 = get_semantic_recommendations(query1)\n",
    "        print(results1['title'])\n",
    "        \n",
    "        # Test 2: A different query\n",
    "        query2 = \"modern storage for shoes\"\n",
    "        print(f\"\\nRecommendations for: '{query2}'\")\n",
    "        results2 = get_semantic_recommendations(query2)\n",
    "        print(results2['title'])\n",
    "        \n",
    "        # Test 3: A query about materials\n",
    "        query3 = \"something made of wood\"\n",
    "        print(f\"\\nRecommendations for: '{query3}'\")\n",
    "        results3 = get_semantic_recommendations(query3)\n",
    "        print(results3['title'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5d569-e276-4778-9420-0692da531d41",
   "metadata": {},
   "source": [
    "# For Open CV part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f40ca18-9746-4ec5-b1c7-41f431b54465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgbeddings in c:\\users\\cyash\\yashenv\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: transformers>=4.17.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from imgbeddings) (4.57.1)\n",
      "Requirement already satisfied: onnxruntime>=1.10.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from imgbeddings) (1.23.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cyash\\yashenv\\lib\\site-packages (from imgbeddings) (12.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyash\\yashenv\\lib\\site-packages (from imgbeddings) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cyash\\yashenv\\lib\\site-packages (from imgbeddings) (1.7.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (25.9.23)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (2.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\cyash\\yashenv\\lib\\site-packages (from onnxruntime>=1.10.0->imgbeddings) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (0.35.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers>=4.17.0->imgbeddings) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.17.0->imgbeddings) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.17.0->imgbeddings) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyash\\yashenv\\lib\\site-packages (from tqdm->imgbeddings) (0.4.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.10.0->imgbeddings) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.10.0->imgbeddings) (3.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers>=4.17.0->imgbeddings) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers>=4.17.0->imgbeddings) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers>=4.17.0->imgbeddings) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers>=4.17.0->imgbeddings) (2025.10.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn->imgbeddings) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn->imgbeddings) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from scikit-learn->imgbeddings) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sympy->onnxruntime>=1.10.0->imgbeddings) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imgbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18cdb331-515e-4a75-8b49-7cf11d156a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\cyash\\yashenv\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\cyash\\yashenv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada68fd2-bb35-4e1e-9197-745a0fd7a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\cyash\\yashenv\\lib\\site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyash\\yashenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->huggingface_hub) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "674d7175-3e21-4f93-9df9-2957d646c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product data loaded.\n",
      "Sample product selected: GOYMFK 1pc Free Standing Shoe Rack, Multi-layer Metal Shoe Cap Rack With 8 Double Hooks For Living Room, Bathroom, Hallway\n",
      "Sample image URL: https://m.media-amazon.com/images/I/416WaLx10jL._SS522_.jpg \n",
      "\n",
      "Loading image embedding model (clip-ViT-B-32)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021d8e21f7a841039811b1b282a38833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cyash\\.cache\\huggingface\\hub\\models--sentence-transformers--clip-ViT-B-32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d83a55ebde494f97694a264f9bc0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a09975eb554b489bb50715cc6cd8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 282, in close\n",
      "    self.disp(bar_style='success', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 282, in close\n",
      "    self.disp(bar_style='success', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 282, in close\n",
      "    self.disp(bar_style='success', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AN ERROR OCCURRED ---\n",
      "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory C:\\Users\\cyash\\.cache\\huggingface\\hub\\models--sentence-transformers--clip-ViT-B-32\\snapshots\\327ab6726d33c0e22f920c83f2ff9e4bd38ca37f\\0_CLIPModel.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import ast\n",
    "import io\n",
    "\n",
    "# --- Step 6.2 (Final Attempt): Prototype Image Embedding with CLIP ---\n",
    "\n",
    "try:\n",
    "    # --- 1. Load Data and Clean Image Column ---\n",
    "    products_df = pd.read_pickle('products_df.pkl')\n",
    "    print(\"Product data loaded.\")\n",
    "\n",
    "    def get_first_image_url(image_str):\n",
    "        \"\"\"\n",
    "        Cleans the 'images' column string and gets the first URL.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            image_list = ast.literal_eval(image_str)\n",
    "            if image_list and isinstance(image_list, list) and len(image_list) > 0:\n",
    "                return image_list[0] # Return the first image URL\n",
    "        except (ValueError, SyntaxError, TypeError):\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    products_df['first_image'] = products_df['images'].apply(get_first_image_url)\n",
    "    sample_product = products_df.dropna(subset=['first_image']).iloc[0]\n",
    "    sample_image_url = sample_product['first_image']\n",
    "    \n",
    "    print(f\"Sample product selected: {sample_product['title']}\")\n",
    "    print(f\"Sample image URL: {sample_image_url}\")\n",
    "\n",
    "    # --- 2. Initialize Image Embedding Model (CLIP) ---\n",
    "    print(\"\\nLoading image embedding model (clip-ViT-B-32)...\")\n",
    "    img_model = SentenceTransformer('clip-ViT-B-32')\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # --- 3. Download Image and Generate Embedding ---\n",
    "    print(\"Downloading sample image...\")\n",
    "    # Download the image from the URL\n",
    "    response = requests.get(sample_image_url, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Open the image from the downloaded content\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "        print(\"Image downloaded and opened successfully.\")\n",
    "\n",
    "        print(\"Generating embedding for the sample image...\")\n",
    "        # Encode the PIL image object\n",
    "        image_embedding = img_model.encode(img)\n",
    "        \n",
    "        print(\"\\n--- Image Embedding Generated Successfully! ---\")\n",
    "        print(f\"Type of embedding: {type(image_embedding)}\")\n",
    "        print(f\"Shape of embedding: {image_embedding.shape}\")\n",
    "        print(\"\\nFirst 10 values of the embedding vector:\")\n",
    "        print(image_embedding[:10])\n",
    "    else:\n",
    "        print(f\"\\n--- ERROR ---\")\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df1004-9fc6-46ec-a673-d48fd5b2c0c3",
   "metadata": {},
   "source": [
    "## Above part is not working for some reason , using core transformers library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4c0334-e8ad-4f6a-83a8-4684f8e8d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\cyash\\yashenv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in c:\\users\\cyash\\yashenv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyash\\yashenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyash\\yashenv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a0cd61-d411-4413-b183-7895c0fc2791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product data loaded.\n",
      "Sample product selected: JOIN IRON Foldable TV Trays for Eating Set of 4 with Stand,Folding TV/Snack Tray Table Set,Folding TV Dinner Tables for Small Space,(Grey)\n",
      "Sample image URL: https://m.media-amazon.com/images/I/41p4d4VJnNL._SS522_.jpg \n",
      "\n",
      "Loading CLIP model and processor directly...\n",
      "Model and processor loaded successfully.\n",
      "Downloading sample image...\n",
      "\n",
      "--- ERROR ---\n",
      "Failed to download image. Status code: 400\n",
      "This specific image URL may be broken or heavily protected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001F0C9D977E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\cyash\\yashenv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import ast\n",
    "import io\n",
    "import torch\n",
    "\n",
    "# --- Step 6.2 (Final Method, Corrected Download): Prototype Image Embedding ---\n",
    "\n",
    "try:\n",
    "    # --- 1. Load Data and Clean Image Column ---\n",
    "    products_df = pd.read_pickle('products_df.pkl')\n",
    "    print(\"Product data loaded.\")\n",
    "\n",
    "    def get_first_image_url(image_str):\n",
    "        try:\n",
    "            image_list = ast.literal_eval(image_str)\n",
    "            if image_list and isinstance(image_list, list) and len(image_list) > 0:\n",
    "                return image_list[0]\n",
    "        except (ValueError, SyntaxError, TypeError):\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    products_df['first_image'] = products_df['images'].apply(get_first_image_url)\n",
    "    \n",
    "    # --- THIS IS THE FIX: Get a *different* sample product ---\n",
    "    # The first image might be broken or protected. Let's try the 5th product.\n",
    "    sample_product = products_df.dropna(subset=['first_image']).iloc[4]\n",
    "    sample_image_url = sample_product['first_image']\n",
    "    \n",
    "    print(f\"Sample product selected: {sample_product['title']}\")\n",
    "    print(f\"Sample image URL: {sample_image_url}\")\n",
    "\n",
    "    # --- 2. Initialize Image Embedding Model (CLIP) ---\n",
    "    print(\"\\nLoading CLIP model and processor directly...\")\n",
    "    model_name = \"openai/clip-vit-base-patch32\"\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "    model = CLIPModel.from_pretrained(model_name)\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "\n",
    "    # --- 3. Download Image and Generate Embedding ---\n",
    "    print(\"Downloading sample image...\")\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # We add a User-Agent header to pretend we are a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(sample_image_url, stream=True, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "        print(\"Image downloaded and opened successfully.\")\n",
    "\n",
    "        print(\"Generating embedding for the sample image...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            inputs = processor(images=img, return_tensors=\"pt\")\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "        \n",
    "        image_embedding = image_features[0]\n",
    "        \n",
    "        print(\"\\n--- Image Embedding Generated Successfully! ---\")\n",
    "        print(f\"Type of embedding: {type(image_embedding)}\")\n",
    "        print(f\"Shape of embedding: {image_embedding.shape}\")\n",
    "        print(\"\\nFirst 10 values of the embedding vector:\")\n",
    "        print(image_embedding[:10])\n",
    "    else:\n",
    "        print(f\"\\n--- ERROR ---\")\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "        print(\"This specific image URL may be broken or heavily protected.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c9c17-094b-4850-a292-616b9679793e",
   "metadata": {},
   "source": [
    "# Creating a mock function , because Amazon servers are not allowing us to downlaod, because it suspects us being not a real person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca1be19-0408-4b6c-be60-05578d9dbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock CV function 'get_image_embedding_mock' created successfully.\n",
      "\n",
      "Testing with sample URL: https://m.media-amazon.com/images/I/416WaLx10jL._SS522_.jpg \n",
      "\n",
      "--- Mock Image Embedding Generated Successfully! ---\n",
      "Type of embedding: <class 'numpy.ndarray'>\n",
      "Shape of embedding: (512,)\n",
      "\n",
      "First 10 values of the mock vector:\n",
      "[0.93848062 0.60454704 0.86079219 0.88536474 0.47567564 0.41950611\n",
      " 0.72127564 0.95537625 0.36057688 0.11199573]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# --- Step 6.3: Create Mock CV Function (Requirement #3) ---\n",
    "\n",
    "# We have already proven we can load the real CLIP model.\n",
    "# Now, we create a mock function to bypass the download block\n",
    "# and keep the project on schedule.\n",
    "\n",
    "# The 'openai/clip-vit-base-patch32' model outputs a 512-dimension vector.\n",
    "EMBEDDING_DIMENSION = 512\n",
    "\n",
    "def get_image_embedding_mock(image_url):\n",
    "    \"\"\"\n",
    "    MOCK FUNCTION: Pretends to download an image and run the CLIP model.\n",
    "    Returns a fake vector of the correct shape (512 dimensions).\n",
    "    \"\"\"\n",
    "    if not image_url or not isinstance(image_url, str):\n",
    "        return None\n",
    "    \n",
    "    # Generate a random vector to simulate the real embedding\n",
    "    mock_embedding = np.random.rand(EMBEDDING_DIMENSION)\n",
    "    return mock_embedding\n",
    "\n",
    "print(\"Mock CV function 'get_image_embedding_mock' created successfully.\")\n",
    "\n",
    "# --- Test the Mock Function ---\n",
    "products_df = pd.read_pickle('products_df.pkl')\n",
    "\n",
    "def get_first_image_url(image_str):\n",
    "    try:\n",
    "        image_list = ast.literal_eval(image_str)\n",
    "        if image_list and isinstance(image_list, list) and len(image_list) > 0:\n",
    "            return image_list[0]\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "products_df['first_image'] = products_df['images'].apply(get_first_image_url)\n",
    "sample_product_url = products_df.dropna(subset=['first_image']).iloc[0]['first_image']\n",
    "\n",
    "print(f\"\\nTesting with sample URL: {sample_product_url}\")\n",
    "\n",
    "# Test the function\n",
    "mock_vector = get_image_embedding_mock(sample_product_url)\n",
    "\n",
    "print(\"\\n--- Mock Image Embedding Generated Successfully! ---\")\n",
    "print(f\"Type of embedding: {type(mock_vector)}\")\n",
    "print(f\"Shape of embedding: {mock_vector.shape}\")\n",
    "print(\"\\nFirst 10 values of the mock vector:\")\n",
    "print(mock_vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fab82-8992-4e22-b1f0-2f82f8aa1d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yashenv)",
   "language": "python",
   "name": "yashenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
